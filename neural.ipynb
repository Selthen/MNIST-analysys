{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sieć neuronowa\n",
    "\n",
    "Sieć neuronowa pozwala nam na stworzenie i wyszkolenie modelu, który będzie się starał jak najlepiej przewidzieć kategorię dla danej wejściowej.\n",
    "\n",
    "W naszym przypadku użyjemy sieci składającej się z 6 warstw:\n",
    "1. Warstwa spłaszczająca - zamienia nam wielowymiarowe dane na jednowymiarową kolumnę.\n",
    "2. Warstwa gęsta? 512 neuronów - każdy neuron tej warstwy jest połączony z każdym poprzedniej.\n",
    "3. Warstwa odrzucająca - zapobiega zbytniemu uczeniu się sieci pod dany zestaw testów.\n",
    "4. Warstwa gęsta? 128 neuronów - \n",
    "5. Warstwa odrzucająca\n",
    "5. Warstwa gęsta? 10 neuronów - finalna warstwa zawierająca tylko 10 neuronów, czyli tyle ile mamy kategorii. Jest to wyjście z naszego modelu. Im większa wartość neuronu tym pewniejsza jest sieć, że jest to ta kategoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Źródła\n",
    "- https://www.tutorialexample.com/understand-dense-layer-fully-connected-layer-in-neural-networks-deep-learning-tutorial/\n",
    "- https://www.tensorflow.org/datasets/keras_example\n",
    "- https://www.theprofessionalprogrammer.com/2018/11/neural-network-dense-layers.html\n",
    "- https://iq.opengenus.org/dense-layer-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Zamieniamy pixele z watrości 0 - 255 na wartości 0.0 - 1.0\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "# num_parallel_calls - pozwala na szybsze wykonanie map poprzez równoległe mapowanie wielu elementów\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "# shuffle bierze buffer_size który ustawiamy na wielkość zbioru żeby na pewno było dobrze pomieszane\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "# dzielenie na części dla każdej generacji\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "categories = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "our_nums = [\"test_0\", \"test_7\"]\n",
    "\n",
    "for i in range(len(our_nums)):\n",
    "    image = io.imread(f\"{our_nums[i]}.png\", as_gray=1)\n",
    "    image_reshaped = image.reshape(-1, 28, 28, 1)\n",
    "\n",
    "    prediction = model.predict(image_reshaped)\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f\"Prediction = {categories[np.argmax(prediction[0])]}\", fontdict={\"fontsize\": 20})\n",
    "    io.imshow(image)\n",
    "\n",
    "    plotable = pd.DataFrame(prediction[0])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(categories)\n",
    "    plt.bar(categories, plotable[0])\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efad3ac9de8e6fd3341e943986d5e70cc8ce6ee85cb19b7b0efac720ad07f338"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit ('jupyter-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
